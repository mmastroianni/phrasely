# Phrasely â€“ Phrase Clustering and Embedding Pipeline (GPUâ€‘Accelerated)
![CI](https://github.com/mmastroianni/phrasely/actions/workflows/ci.yml/badge.svg)

## ğŸ§  Overview
Phrasely is a modular, GPUâ€‘accelerated pipeline for clustering and analyzing large phrase datasets. It uses **Sentence Transformers** for embeddings, **SVD/PCA** for dimensionality reduction, and **cuML HDBSCAN** for clustering on NVIDIA GPUs via the **RAPIDS** suite. The project is structured for clean testability, reproducibility, and eventual openâ€‘source release.

---

## âš™ï¸ Features
- Modular pipeline: load â†’ embed â†’ reduce â†’ cluster â†’ medoid selection
- GPU acceleration with RAPIDS (cuML / cuDF / CuPy)
- CPU fallback for nonâ€‘GPU systems
- Testâ€‘driven development layout (`src/` + `tests/`)
- Ready for PyCharm and Jupyter integration
- Fully reproducible via micromamba environments

---

## ğŸ§± Directory Structure
```
phrasely/
â”œâ”€â”€ Makefile
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ pytest.ini
â”œâ”€â”€ environment.yaml              # GPU-default (RAPIDS)
â”œâ”€â”€ environment-cpu.yaml          # CPU fallback
â”œâ”€â”€ src/
â”‚   â””â”€â”€ phrasely/
â”‚       â”œâ”€â”€ pipeline.py
â”‚       â”œâ”€â”€ utils/
â”‚       â”œâ”€â”€ data_loading/
â”‚       â”œâ”€â”€ embeddings/
â”‚       â”œâ”€â”€ reduction/
â”‚       â”œâ”€â”€ clustering/
â”‚       â””â”€â”€ medoids/
â”œâ”€â”€ tests/
â”œâ”€â”€ notebooks/
â””â”€â”€ README.md
```

---

## ğŸš€ Setup Instructions

### 1ï¸âƒ£ Create Environment (GPU Default)
```bash
micromamba create -n phrasely -f environment.yaml
micromamba activate phrasely
```
If using a CPUâ€‘only system:
```bash
micromamba create -n phrasely-cpu -f environment-cpu.yaml
micromamba activate phrasely-cpu
```

### 2ï¸âƒ£ Verify GPU Access
```bash
python tests/test_gpu_setup.py
```
You should see your GPU name and a successful cuML HDBSCAN run.

---

## ğŸ§© PyCharm Integration
1. Open **Settings â†’ Project â†’ Python Interpreter**.
2. Add an interpreter: **Existing Environment**.
3. Point to your micromamba Python binary, e.g.:
   ```
   /home/michael/micromamba/envs/phrasely/bin/python
   ```
4. Rename it to â€œphraselyâ€‘gpu (micromamba)â€ for clarity.

PyCharm will index all GPUâ€‘enabled packages (cuML, cuDF, CuPy, etc.).

---

## ğŸ““ Jupyter Kernel Setup
To use the environment in notebooks:
```bash
micromamba activate phrasely
micromamba install ipykernel
python -m ipykernel install --user --name phrasely --display-name "Phrasely (GPU)"
```
Then select **Phrasely (GPU)** from the kernel list in PyCharm or JupyterLab.

---

## ğŸ§  Pipeline Overview
Each step is modular and unitâ€‘tested:
- **`data_loading`** â†’ Load phrases from CSV or other sources.
- **`embeddings`** â†’ Generate sentence embeddings (Sentence Transformers).
- **`reduction`** â†’ Dimensionality reduction (SVD / PCA).
- **`clustering`** â†’ HDBSCAN (GPU via cuML or CPU fallback).
- **`medoids`** â†’ Select representative phrases per cluster.

Run the pipeline:
```bash
python -m phrasely.pipeline --input data/sample_phrases.csv --output results.csv
```

---

## ğŸ§° Developer Notes
- Use `pytest -v` to run all tests.
- Use `make format` to auto-format the codebase with **Black** and **isort**.
- Use `make lint` to run **flake8** (style) and **mypy** (type checking).
- Use `make install` to generate editable dev install.
- Use `make gpu-test` (optional) to run GPU sanity check.

---

## ğŸ“„ License
MIT Â© 2025 Michael Mastroianni
