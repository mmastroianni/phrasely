{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17e13413-558d-44fd-b664-51e487a98c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/micromamba/envs/phrasely-gpu/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "os.environ[\"HF_DATASETS_OFFLINE\"] = \"0\"\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"/tmp\"     # points to temp dir\n",
    "os.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\"\n",
    "os.environ[\"HF_DATASETS_DISABLE_CACHING\"] = \"1\"  # üëà full off switch\n",
    "\n",
    "project_root = \"/home/michael/workspace/phrasely\"\n",
    "sys.path.insert(0, os.path.join(project_root, \"src\"))\n",
    "os.chdir(project_root)\n",
    "\n",
    "\n",
    "import random\n",
    "import warnings\n",
    "from tqdm import TqdmWarning, tqdm\n",
    "import pandas as pd\n",
    "from phrasely.pipeline import run_pipeline\n",
    "from phrasely.data_loading.cc100_loader import CC100Loader\n",
    "from phrasely.embeddings.phrase_embedder import PhraseEmbedder\n",
    "from phrasely.data_loading.cc100_offline_loader import CC100OfflineLoader\n",
    "import logging\n",
    "from phrasely.reduction.visualization_reducer import VisualizationReducer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=TqdmWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "915aa3a5-f7ed-4e12-b499-21a24b49a1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logger(name: str) -> logging.Logger:\n",
    "    logger = logging.getLogger(name)\n",
    "    if not logger.handlers:\n",
    "        handler = logging.StreamHandler(sys.stdout)\n",
    "        formatter = logging.Formatter(\"%(message)s\")\n",
    "        handler.setFormatter(formatter)\n",
    "        logger.addHandler(handler)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc744a1b-e2d0-4c17-a92d-652938032c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger phrasely (INFO)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setup_logger('phrasely')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d22e94f6-715d-46f4-bb1f-078c210a42ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Phrasely pipeline...\n",
      "Detected GPU VRAM: 3.8 GB\n",
      "Adaptive GPU limits ‚Äî SVD: 190,000 rows, HDBSCAN: 190,000 rows.\n",
      "‚ñ∂Ô∏è  Loading and embedding phrases...\n",
      "PhraseEmbedder using model=paraphrase-MiniLM-L6-v2, device=cuda, VRAM‚âà3.8 GB, batch_size=8\n",
      "Converted model to fp16 for reduced VRAM usage.\n",
      "‚ö†Ô∏è  Found 236 shards; limiting to first 20 to avoid memory overflow.\n",
      "Streaming 20 chunks from data_cache/cc100\n",
      "Yielding 50,000 rows from cc100-train-00000-00000-of-NNNNN.arrow (1/62)\n",
      "Loading cached embeddings from data_cache/embeddings_paraphrase-MiniLM-L6-v2_f7bf034570992803f5b1fb054a25ccfd.npy\n",
      "‚ö†Ô∏è Embedding size mismatch in batch 1: 20000 embeddings vs 50000 phrases. Truncating to smallest length.\n",
      "Streamed batch 1: 20,000 phrases\n",
      "Yielding 50,000 rows from cc100-train-00000-00000-of-NNNNN.arrow (2/62)\n",
      "Loading cached embeddings from data_cache/embeddings_paraphrase-MiniLM-L6-v2_6d7e846e588113ccb2b999071a7f046f.npy\n",
      "Streamed batch 2: 50,000 phrases\n",
      "Yielding 50,000 rows from cc100-train-00000-00000-of-NNNNN.arrow (3/62)\n",
      "Loading cached embeddings from data_cache/embeddings_paraphrase-MiniLM-L6-v2_faabd218ca41ea6381f8ec6fa13a4eb4.npy\n",
      "‚ö†Ô∏è Embedding size mismatch in batch 3: 20000 embeddings vs 50000 phrases. Truncating to smallest length.\n",
      "Streamed batch 3: 20,000 phrases\n",
      "Yielding 50,000 rows from cc100-train-00000-00000-of-NNNNN.arrow (4/62)\n",
      "Loading cached embeddings from data_cache/embeddings_paraphrase-MiniLM-L6-v2_c8a1d4065439d27750f60cdb51b2fcd7.npy\n",
      "Streamed batch 4: 50,000 phrases\n",
      "Reached max_phrases limit; stopping stream.\n",
      "Streamed total: 100,000 phrases, 100,000 embeddings.\n",
      "üßπ Freed GPU memory after embedding.\n",
      "Loading and embedding phrases completed in 3.817s.\n",
      "‚ñ∂Ô∏è  Reducing dimensions...\n",
      "SVDReducer: using GPU backend for TruncatedSVD.\n",
      "SVDReducer: reduced 384 ‚Üí 100dimensions.\n",
      "üßπ Freed GPU memory after SVD reduction.\n",
      "Reducing dimensions completed in 0.381s.\n",
      "‚ñ∂Ô∏è  Clustering phrases...\n",
      "HDBSCANClusterer: using GPU backend.\n",
      "HDBSCANClusterer: found 8 clusters (+ noise).\n",
      "üßπ Freed GPU memory after clustering.\n",
      "Clustering phrases completed in 10.359s.\n",
      "‚ñ∂Ô∏è  Selecting medoids...\n",
      "Selected 8 medoids across 8 clusters.\n",
      "Selecting medoids completed in 0.046s.\n",
      "‚úÖ Pipeline complete: 8 clusters, 8 medoids.\n",
      "Saving PipelineResult to data_cache/run_cc100_100k.npz and data_cache/run_cc100_100k_meta.json\n",
      "\n",
      "‚úÖ End-to-end pipeline finished successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_phrases': 100000,\n",
       " 'n_clusters': 8,\n",
       " 'n_medoids': 8,\n",
       " 'embedding_dim': 384,\n",
       " 'reduced_dim': 100}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = run_pipeline(\n",
    "    CC100OfflineLoader,\n",
    "    loader_kwargs={\n",
    "        \"arrow_dir\": \"data_cache/cc100\",\n",
    "        \"language\": \"\",\n",
    "        \"max_files\": 20,\n",
    "        \"max_phrases\": 100_000,\n",
    "        \"batch_size\": 50_000,\n",
    "    },\n",
    "    stream=True,\n",
    "    use_gpu=True,\n",
    "    min_cluster_size=5,   # üëà adjust here\n",
    "    min_samples=2         # üëà optional fine-tuning\n",
    ")\n",
    "\n",
    "\n",
    "result.save(\"data_cache/run_cc100_100k\")\n",
    "print(\"\\n‚úÖ End-to-end pipeline finished successfully!\")\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbdf5d2-1477-46ef-b043-fdc60180f02f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00563b33-67e3-47e6-b194-8a34c4a15e04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf4a176c-f560-4e2f-9e96-9b44ba4f8f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisualizationReducer: method=umap, GPU=True, seed=42\n",
      "‚ö†Ô∏è  GPU UMAP may be nondeterministic even with a fixed random_state.\n",
      "VisualizationReducer: reduced 100 ‚Üí 2 dims, mean=[ 3.8703678e-08 -1.7868042e-07], std=[0.9999806 0.999987 ]\n",
      "Clipped outliers: kept 99994 / 100000 points\n",
      "Saved cluster plot to data_cache/clusters.png\n"
     ]
    }
   ],
   "source": [
    "from phrasely.evaluation.visualizer import plot_clusters_2d\n",
    "\n",
    "viz_reducer = VisualizationReducer(method=\"umap\", n_components=2, use_gpu=True, random_state=42)\n",
    "viz_2d = viz_reducer.reduce(result.reduced)\n",
    "# Normalize for stable plotting\n",
    "viz_2d = (viz_2d - viz_2d.mean(axis=0)) / (viz_2d.std(axis=0) + 1e-9)\n",
    "\n",
    "\n",
    "plot_clusters_2d(\n",
    "    viz_2d,\n",
    "    result.labels,\n",
    "    texts=result.medoids,\n",
    "    phrases=result.phrases,\n",
    "    dbcv_score=0.71,  # optional if you have evaluator\n",
    "    savepath='data_cache/clusters.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b250d2a8-1add-4676-86dc-cb1d3178ecac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 1 medoids across 1 clusters.\n",
      "Type: <class 'tuple'>\n",
      "Output: ([1], ['b'])\n"
     ]
    }
   ],
   "source": [
    "from phrasely.medoids.medoid_selector import MedoidSelector\n",
    "import numpy as np\n",
    "\n",
    "phrases = [\"a\", \"b\", \"c\"]\n",
    "embeddings = np.array([[1.0, 0.0], [0.7071, 0.7071], [0.0, 1.0]])\n",
    "labels = np.array([0, 0, 0])\n",
    "\n",
    "selector = MedoidSelector(metric=\"cosine\", exact_threshold=10)\n",
    "out = selector.select(phrases, embeddings, labels)\n",
    "print(\"Type:\", type(out))\n",
    "print(\"Output:\", out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed6f20b-d40e-4352-b5ca-75f2edbe896d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Phrasely (GPU)",
   "language": "python",
   "name": "phrasely-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
